{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C://Users//jack//Documents//stock_database_pipeline//price_prediction_pipeline//dataset//update//update_pre_cleantestRouters.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns except , 'price', 'title', 'link', 'condition', 'brand', 'type', 'seller_notes'\n",
    "df = df[['price', 'title', 'link', 'condition', 'brand', 'type', 'seller notes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all unique values in the brand and type columns\n",
    "print(df['brand'].unique())\n",
    "\n",
    "df['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pd.read_csv('C://Users//jack\\Documents//stock_database_pipeline//price_prediction_pipeline//source_csv//merged_inventory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter source for 'server' in the 'product type' column\n",
    "source = source[source['ProductType'] == 'router']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regex pattern to match any model in the source['Model'] list\n",
    "pattern = '|'.join(re.escape(device) for device in source['Model'])\n",
    "\n",
    "# Extract the model from the title using the regex pattern\n",
    "df['model'] = df['title'].str.extract(f'({pattern})', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regex pattern to match any model in the source['Manufacturer'] list\n",
    "pattern = '|'.join(re.escape(device) for device in source['Manufacturer'])\n",
    "\n",
    "# Extract the model from the title using the regex pattern\n",
    "df['brand'] = df['title'].str.extract(f'({pattern})', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns\n",
    "df = df[['price', 'brand', 'model', 'title', 'type', 'link', 'condition', 'seller notes']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where pattern is present in the title\n",
    "pattern = r'shower|wipers|wiper|joblot|job|x4|laptop|thinkpad|rails|kit|cable|cables|screws|screw|mount|mounts|mounting|bracket|brackets|bezel|bezels|cover|covers|tray|trays|sled|sleds|psu|power supply|power supplies|fan|fans|caddy|caddies|heatsink'\n",
    "\n",
    "# Drop NaN values in the title column\n",
    "df = df.dropna(subset=['title'])\n",
    "\n",
    "# Drop rows where pattern is present in the title\n",
    "df = df[~df['title'].str.contains(pattern, case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows missing a model\n",
    "df = df.dropna(subset=['model'])\n",
    "\n",
    "df = df[['price', 'brand', 'model', 'title', 'type', 'link', 'condition', 'seller notes']]\n",
    "\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data to a new csv file\n",
    "df.to_csv('C://Users//jack//Documents//stock_database_pipeline//price_prediction_pipeline//dataset//update//update_cleantestRouters.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "df = df[['status', 'price', 'brand', 'model', 'title', 'type', 'link', 'condition', 'seller notes']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'model' and 'brand', then calculate the average price and keep the status\n",
    "unique_df = df.groupby(['brand', 'model']).agg(\n",
    "    status=('status', 'first'),  # Assuming status is the same within each group\n",
    "    average_price=('price', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "print(unique_df)\n",
    "\n",
    "unique_df['status'] = unique_df['average_price'].astype(float).apply(lambda x: 'sell' if x >= 50 else 'scrap')\n",
    "print(unique_df)\n",
    "# Drop 'avereage_price' column\n",
    "unique_df = unique_df.drop(columns=['average_price'])\n",
    "\n",
    "# Rename columns\n",
    "unique_df.columns = ['Manufacturer', 'Model', 'Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capitalize the first letter of each word in 'Manufacturer' and 'Model' columns\n",
    "unique_df['Manufacturer'] = unique_df['Manufacturer'].str.title()\n",
    "unique_df['Model'] = unique_df['Model'].str.title()\n",
    "unique_df['Status'] = unique_df['Status'].str.title()\n",
    "\n",
    "# Merge all three columns into one separated by a ; character\n",
    "unique_df['Manufacturer;Model;Status'] =unique_df['Manufacturer'] + ';' +unique_df['Model'] + ';' +unique_df['Status']\n",
    "\n",
    "# Drop the 'Manufacturer' and 'Model' columns\n",
    "unique_df = unique_df.drop(columns=['Manufacturer', 'Model', 'Status'])\n",
    "\n",
    "unique_df.head()\n",
    "\n",
    "# Save the cleaned data to a new csv file\n",
    "unique_df.to_csv('C://Users//jack//Documents//stock_database_pipeline//price_prediction_pipeline//source_csv//glpi_update_router_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
