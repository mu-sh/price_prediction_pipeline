{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "aiken = pd.read_csv('C://Users//jack//Documents//aiken_upload_pipeline//Python_scripts//AikenTempCSV//awb_db_complete11.04.2024.csv')\n",
    "blancco = pd.read_csv('C://Users//jack//Documents//aiken_upload_pipeline//Python_scripts//exports//2024-04-12_merged_export.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "display(aiken.head())\n",
    "display(blancco.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "display(aiken.columns)\n",
    "display(blancco.columns)\n",
    "\n",
    "# save column lists as csv files\n",
    "aiken_cols = pd.DataFrame(aiken.columns)\n",
    "aiken_cols.to_csv('C://Users//jack//Documents//price_prediction_pipeline//csv//databasemergerTEST//aiken_cols.csv', index=False, header=False)\n",
    "\n",
    "blancco_cols = pd.DataFrame(blancco.columns)\n",
    "blancco_cols.to_csv('C://Users//jack//Documents//price_prediction_pipeline//csv//databasemergerTEST//blancco_cols.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "blancco['CollectionID'] = blancco['Business name'].str.split('-').str[1]\n",
    "\n",
    "# Drop columns that are not needed\n",
    "blancco = blancco.drop(['Business name', 'BARCODE_y', 'Barcode_y'], axis=1)\n",
    "\n",
    "blancco['Barcode'] = blancco['BARCODE_x'].combine_first(blancco['Barcode_x'])\n",
    "\n",
    "blancco = blancco.drop(['BARCODE_x', 'Barcode_x'], axis=1)\n",
    "\n",
    "display(blancco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Separate multiple drive interface type entries into individual columns\n",
    "\n",
    "df_split = blancco['Disk interface type'].str.split('/', expand=True)\n",
    "\n",
    "df_split = df_split.iloc[:, :4]\n",
    "\n",
    "df_split.columns = ['Disk1 type', 'Disk2 type', 'Disk3 type', 'Disk4 type']\n",
    "df = blancco.join(df_split)\n",
    "\n",
    "df_display = df.loc[:, 'Disk model':]\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df_display)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "df_split = blancco['Disk model'].str.split('/', expand=True)\n",
    "\n",
    "df_split = df_split.iloc[:, :4]\n",
    "\n",
    "df_split.columns = ['Disk1 model', 'Disk2 model', 'Disk3 model', 'Disk4 model']\n",
    "df = df.join(df_split)\n",
    "\n",
    "df_display = df.loc[:, 'Disk model':]\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df_display)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_split = blancco['Disk serial'].str.split('/', expand=True)\n",
    "\n",
    "df_split = df_split.iloc[:, :4]\n",
    "\n",
    "df_split.columns = ['Disk1 serial', 'Disk2 serial', 'Disk3 serial', 'Disk4 serial']\n",
    "df = df.join(df_split)\n",
    "\n",
    "df_display = df.loc[:, 'Disk model':]\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df_display)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_split = blancco['Disk vendor'].str.split('/', expand=True)\n",
    "\n",
    "df_split = df_split.iloc[:, :4]\n",
    "\n",
    "df_split.columns = ['Disk1 vendor', 'Disk2 vendor', 'Disk3 vendor', 'Disk4 vendor']\n",
    "df = df.join(df_split)\n",
    "\n",
    "df_display = df.loc[:, 'Disk serial':]\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df_display)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_split = df['Disk capacity'].str.split('/', expand=True)\n",
    "\n",
    "df_split = df_split.iloc[:, :4]\n",
    "\n",
    "df_split.columns = ['Disk1 capacity', 'Disk2 capacity', 'Disk3 capacity', 'Disk4 capacity']\n",
    "blancco = df.join(df_split)\n",
    "\n",
    "df_display = df.loc[:, 'Disk capacity':]\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df_display)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "header_mapping = {\n",
    "    'Barcode':'UnitID', \n",
    "    'CollectionID':'CollectionID', \n",
    "    'Erasure date':'Audited', \n",
    "    'System chassis type':'ProductType', \n",
    "    'System manufacturer':'Manufacturer',\n",
    "    'System model':'Model', \n",
    "    'System serial':'SerialNumber', \n",
    "    'Display resolution':'Resolution', \n",
    "    'CPU model':'Processor',\n",
    "    'CPU generation':'ProcGen', \n",
    "    'Memory capacity':'TotalRAM', \n",
    "    'Memory type':'RAM1Type', \n",
    "    'Disk1 capacity':'Storage1Size', \n",
    "    'Disk2 capacity':'Storage2Size', \n",
    "    'Disk3 capacity':'Storage3Size', \n",
    "    'Disk4 capacity':'Storage4Size',\n",
    "    'Disk1 type':'Storage1Type',\n",
    "    'Disk2 type':'Storage2Type',\n",
    "    'Disk3 type':'Storage3Type',\n",
    "    'Disk4 type':'Storage4Type',\n",
    "    'Disk1 model':'Storage1Model', \n",
    "    'Disk2 model':'Storage2Model', \n",
    "    'Disk3 model':'Storage3Model', \n",
    "    'Disk4 model':'Storage4Model', \n",
    "    'Disk1 serial':'Storage1Serial', \n",
    "    'Disk2 serial':'Storage2Serial', \n",
    "    'Disk3 serial':'Storage3Serial', \n",
    "    'Disk4 serial':'Storage4Serial',\n",
    "    'Disk1 vendor':'Storage1Manufacturer', \n",
    "    'Disk2 vendor':'Storage2Manufacturer', \n",
    "    'Disk3 vendor':'Storage3Manufacturer', \n",
    "    'Disk4 vendor':'Storage4Manufacturer', \n",
    "    'Battery model':'BatteryModel', \n",
    "    'Video card model':'GPU', \n",
    "    'Erasure technician':'User'\n",
    "}\n",
    "\n",
    "blancco = blancco.rename(columns=header_mapping)\n",
    "\n",
    "cols_to_drop = ['Maximum CPU frequency', 'Video card vendor', 'Report verification', 'Erasure target model', 'Disk index', 'Disk ID', 'Disk capacity', 'Disk model', 'Disk serial', 'Disk vendor', 'Disk interface type']\n",
    "\n",
    "blancco = blancco.drop(cols_to_drop, axis=1)\n",
    "\n",
    "display(blancco)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Add 'source' column to each DataFrame\n",
    "aiken['source'] = 'aiken'\n",
    "blancco['source'] = 'blancco'\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "df = pd.concat([aiken, blancco], ignore_index=True)\n",
    "\n",
    "# Sort the DataFrame by date\n",
    "df = df.sort_values(by='Audited')\n",
    "\n",
    "# Reset the index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Lowercase all column headers\n",
    "df.columns = map(str.lower, df.columns)\n",
    "\n",
    "# Filter Nan values from 'collectionid' column\n",
    "df = df[df['collectionid'].notna()]\n",
    "\n",
    "# Drop rows where j is not in the collectionid column\n",
    "df = df[df['collectionid'].str.contains('J')]\n",
    "\n",
    "# Strip leading and trailing whitespace from collectionid column\n",
    "df['collectionid'] = df['collectionid'].str.strip()\n",
    "\n",
    "# Lowercase all values in all cells in the DataFrame\n",
    "#df = df.apply(lambda x: x.astype(str).str.lower())\n",
    "\n",
    "# Filter df by collectionID for string begining with 'j'\n",
    "#df = df[df['collectionid'].str.startswith('j')]\n",
    "\n",
    "# ensure that unitid and lotid are intergers\n",
    "#df['unitid'] = df['unitid'].astype(int)\n",
    "\n",
    "# Convert 'lotid_x' to float first, then to int to handle floating-point strings\n",
    "df['lotid_x'] = df['lotid_x'].fillna(0).astype(float).astype(int)\n",
    "\n",
    "# Display the rows which contain blancco in the source column\n",
    "#df = df[df['source'].str.contains('blancco')]\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('C://Users//jack//Documents//price_prediction_pipeline//csv//databasemergerTEST//stock_database.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
