{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 8574, 0: 141})\n",
      "Counter({1: 8574, 0: 8574})\n",
      "MSE: 0.0041415782288882754\n",
      "RMSE: 0.06435509481686959\n",
      "R^2 score: 0.9834336870844469\n",
      "                     Model       MSE      RMSE       R^2\n",
      "0  Random Forest Regressor  0.004142  0.064355  0.983434\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# define dataset\n",
    "df = pd.read_csv('C:/Users/jack/Documents/EbayMarketScraping/Scraping_bs4_ebay-main/02-11-23_clean_output8719row.csv')\n",
    "\n",
    "# Remove duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Remove irrelevant columns\n",
    "df.drop(['title', 'sold_date', 'link', 'seller notes', 'series', 'operating system', 'type', 'condition', 'processor', 'features', 'item number'], axis=1, inplace=True)\n",
    "\n",
    "# Handle missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "\n",
    "# Convert the 'price' variable to a binary variable\n",
    "threshold = 50\n",
    "y = np.where(y > threshold, 1, 0)\n",
    "\n",
    "# summarize class distribution\n",
    "print(Counter(y))\n",
    "# define oversampling strategy\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "# fit and apply the transform\n",
    "X_over, y_over = oversample.fit_resample(X, y)\n",
    "# summarize class distribution\n",
    "print(Counter(y_over))\n",
    "\n",
    "\n",
    "# Convert categorial variables with label encoder\n",
    "categorical_cols = ['brand', 'processor i series', 'processor generation', 'storage type','gpu', 'model']\n",
    "le = LabelEncoder()\n",
    "\n",
    "# apply label encoder on categorical feature columns\n",
    "X[categorical_cols] = X[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "\n",
    "# define oversampling strategy\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "# fit and apply the transform\n",
    "X_over, y_over = oversample.fit_resample(X, y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state=1, stratify=y_over)\n",
    "\n",
    "# Create a random forest regressor\n",
    "reg = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the regressor\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# Calculate the metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R^2 score: {r2}')\n",
    "\n",
    "# Add the results to the dataframe\n",
    "results = {'Model': 'Random Forest Regressor',\n",
    "           'MSE': mse,\n",
    "           'RMSE': rmse,\n",
    "           'R^2': r2}\n",
    "\n",
    "\n",
    "# Create a dataframe from the dictionary\n",
    "output = pd.DataFrame([results])\n",
    "print(output.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV RFR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   7.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   6.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   6.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   7.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   6.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   6.8s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   6.6s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   6.5s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   5.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.3s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_absolute_error, explained_variance_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_dist = {\n",
    "    'n_estimators': [10, 50, 100, 200, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Define custom scoring functions\n",
    "def mse(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def r2(y_true, y_pred):\n",
    "    return r2_score(y_true, y_pred)\n",
    "\n",
    "# Define the scoring metrics\n",
    "scoring = {\n",
    "    'MAE': make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    'EVS': make_scorer(explained_variance_score),\n",
    "    'MSE': make_scorer(mse),\n",
    "    'RMSE': make_scorer(rmse),\n",
    "    'R2': make_scorer(r2)\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=reg, param_distributions=param_dist, scoring=scoring, refit='MAE', n_iter=10, cv=5, verbose=2, random_state=42)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the results of the best model\n",
    "best_results = random_search.cv_results_\n",
    "\n",
    "# Convert numpy arrays to lists\n",
    "for key in best_results.keys():\n",
    "    if isinstance(best_results[key], np.ndarray):\n",
    "        best_results[key] = best_results[key].tolist()\n",
    "\n",
    "# Log the performance of each model\n",
    "log_file = 'model_performance_log.json'\n",
    "data = []\n",
    "\n",
    "if os.path.exists(log_file):\n",
    "    try:\n",
    "        with open(log_file, 'r') as file:\n",
    "            data = json.load(file)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"JSONDecodeError encountered. Initialized data as an empty list.\")\n",
    "\n",
    "data.append(best_results)\n",
    "with open(log_file, 'w') as file:\n",
    "    json.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display results of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Create a dataframe with the actual and predicted values\u001b[39;00m\n\u001b[0;32m      4\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual\u001b[39m\u001b[38;5;124m'\u001b[39m: y_test, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted\u001b[39m\u001b[38;5;124m'\u001b[39m: y_pred})\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Create a dataframe with the actual and predicted values\n",
    "results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "\n",
    "# Create a scatter plot\n",
    "fig = px.scatter(results_df, x='Actual', y='Predicted', title='Actual vs Predicted')\n",
    "\n",
    "# Add a diagonal line for reference\n",
    "fig.add_shape(type='line', x0=results_df['Actual'].min(), y0=results_df['Actual'].min(),\n",
    "              x1=results_df['Actual'].max(), y1=results_df['Actual'].max(),\n",
    "              line=dict(color='red', width=2, dash='dash'))\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and save best performing model as checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0036185125148577133\n",
      "RMSE: 0.06015407313605383\n",
      "R^2 score: 0.9855259499405692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_checkpoint.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from joblib import dump\n",
    "\n",
    "# Load the log file\n",
    "with open('model_performance_log.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hyperparameters = random_search.best_params_\n",
    "\n",
    "# Initialize a new model with the best hyperparameters\n",
    "model = RandomForestRegressor(**best_hyperparameters)\n",
    "\n",
    "# Fit the model on your data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Display the performance metrics\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R^2 score: {r2}')\n",
    "\n",
    "\n",
    "# Save the model\n",
    "dump(model, 'model_checkpoint.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
