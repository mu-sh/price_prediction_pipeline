{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Server Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C://Users//jack//Documents//stock_database_pipeline//price_prediction_pipeline//dataset//update//update_pre_cleantestServers2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns except , 'price', 'title', 'link', 'condition', 'brand', 'type', 'seller_notes'\n",
    "df = df[['price', 'title', 'link', 'condition', 'brand', 'type', 'seller notes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all unique values in the brand and type columns\n",
    "print(df['brand'].unique())\n",
    "\n",
    "df['type'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pd.read_csv('C://Users//jack\\Documents//stock_database_pipeline//price_prediction_pipeline//source_csv//merged_inventory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter source for 'server' in the 'product type' column\n",
    "source = source[source['ProductType'] == 'server']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source.value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regex pattern to match any model in the source['Model'] list\n",
    "pattern = '|'.join(re.escape(device) for device in source['Model'])\n",
    "\n",
    "# Extract the model from the title using the regex pattern\n",
    "df['model'] = df['title'].str.extract(f'({pattern})', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regex pattern to match any model in the source['Manufacturer'] list\n",
    "pattern = '|'.join(re.escape(device) for device in source['Manufacturer'])\n",
    "\n",
    "# Extract the model from the title using the regex pattern\n",
    "df['brand'] = df['title'].str.extract(f'({pattern})', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['brand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows with NaN values in the 'brand' column\n",
    "df = df.dropna(subset=['brand'])\n",
    "\n",
    "df['brand'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns\n",
    "df = df[['price', 'brand', 'model', 'title', 'type', 'link', 'condition', 'seller notes']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regex pattern to match any string starting with 'x' followed by one or more numeric characters, not preceded by a hyphen\n",
    "pattern = r'(?<!-)\\bx\\d+\\b'\n",
    "\n",
    "# Extract the model from the title using the regex pattern only if Model is NaN\n",
    "df.loc[df['model'].isna(), 'model'] = df.loc[df['model'].isna(), 'title'].str.extract(f'({pattern})', expand=False)\n",
    "\n",
    "# Display the DataFrame to verify the results\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regex pattern to match any string starting with 'x' followed by one or more numeric characters\n",
    "pattern = r'\\bt\\d+'\n",
    "\n",
    "# Extract the model from the title using the regex pattern only if Model is NaN\n",
    "df.loc[df['model'].isna(), 'model'] = df.loc[df['model'].isna(), 'title'].str.extract(f'({pattern})', expand=False)\n",
    "\n",
    "# Display the DataFrame to verify the results\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regex pattern to match any string starting with 'x' followed by one or more numeric characters\n",
    "pattern = r'\\bm\\d+'\n",
    "\n",
    "# Extract the model from the title using the regex pattern only if Model is NaN\n",
    "df.loc[df['model'].isna(), 'model'] = df.loc[df['model'].isna(), 'title'].str.extract(f'({pattern})', expand=False)\n",
    "\n",
    "# Display the DataFrame to verify the results\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regex pattern to match any string starting with 'x' followed by one or more numeric characters\n",
    "pattern = r'\\bdl\\d+'\n",
    "\n",
    "# Extract the model from the title using the regex pattern only if Model is NaN\n",
    "df.loc[df['model'].isna(), 'model'] = df.loc[df['model'].isna(), 'title'].str.extract(f'({pattern})', expand=False)\n",
    "\n",
    "# Display the DataFrame to verify the results\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regex pattern to match any string starting with 'x' followed by one or more numeric characters\n",
    "pattern = r'\\bd\\d+'\n",
    "\n",
    "# Extract the model from the title using the regex pattern only if Model is NaN\n",
    "df.loc[df['model'].isna(), 'model'] = df.loc[df['model'].isna(), 'title'].str.extract(f'({pattern})', expand=False)\n",
    "\n",
    "# Display the DataFrame to verify the results\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regex pattern to match any string starting with 'x' followed by one or more numeric characters\n",
    "pattern = r'\\br\\d+'\n",
    "\n",
    "# Extract the model from the title using the regex pattern only if Model is NaN\n",
    "df.loc[df['model'].isna(), 'model'] = df.loc[df['model'].isna(), 'title'].str.extract(f'({pattern})', expand=False)\n",
    "\n",
    "# Display the DataFrame to verify the results\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regex pattern to match any string starting with 'x' followed by one or more numeric characters\n",
    "pattern = r'\\bbl\\d+'\n",
    "\n",
    "# Extract the model from the title using the regex pattern only if Model is NaN\n",
    "df.loc[df['model'].isna(), 'model'] = df.loc[df['model'].isna(), 'title'].str.extract(f'({pattern})', expand=False)\n",
    "\n",
    "# Display the DataFrame to verify the results\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regex pattern to match any string starting with 'x' followed by one or more numeric characters\n",
    "pattern = r'\\bml\\d+'\n",
    "\n",
    "# Extract the model from the title using the regex pattern only if Model is NaN\n",
    "df.loc[df['model'].isna(), 'model'] = df.loc[df['model'].isna(), 'title'].str.extract(f'({pattern})', expand=False)\n",
    "\n",
    "# Display the DataFrame to verify the results\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regex pattern to match any string starting with 'x' followed by one or more numeric characters\n",
    "pattern = r'\\bp\\d+'\n",
    "\n",
    "# Extract the model from the title using the regex pattern only if Model is NaN\n",
    "df.loc[df['model'].isna(), 'model'] = df.loc[df['model'].isna(), 'title'].str.extract(f'({pattern})', expand=False)\n",
    "\n",
    "# Display the DataFrame to verify the results\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regex pattern to match any string starting with 'x' followed by one or more numeric characters\n",
    "pattern = r'\\bc\\d+'\n",
    "\n",
    "# Extract the model from the title using the regex pattern only if Model is NaN\n",
    "df.loc[df['model'].isna(), 'model'] = df.loc[df['model'].isna(), 'title'].str.extract(f'({pattern})', expand=False)\n",
    "\n",
    "# Display the DataFrame to verify the results\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regex pattern to match any string starting with 'cse' followed by one or more numeric characters, optionally including hyphens and an optional letter at the end\n",
    "pattern = r'\\bcse[-\\d]+[a-zA-Z]?\\b'\n",
    "\n",
    "# Extract the model from the title using the regex pattern only if Model is NaN\n",
    "df.loc[df['model'].isna(), 'model'] = df.loc[df['model'].isna(), 'title'].str.extract(f'({pattern})', expand=False)\n",
    "\n",
    "# Display the DataFrame to verify the results\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regex pattern to match any string starting with 'x' followed by one or more numeric characters\n",
    "pattern = r'\\bg\\d+'\n",
    "\n",
    "# Extract the model from the title using the regex pattern only if Model is NaN\n",
    "df.loc[df['model'].isna(), 'model'] = df.loc[df['model'].isna(), 'title'].str.extract(f'({pattern})', expand=False)\n",
    "\n",
    "# Display the DataFrame to verify the results\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regex pattern to match any string starting with 'x' followed by one or more numeric characters\n",
    "pattern = r'\\bnx\\d+'\n",
    "\n",
    "# Extract the model from the title using the regex pattern only if Model is NaN\n",
    "df.loc[df['model'].isna(), 'model'] = df.loc[df['model'].isna(), 'title'].str.extract(f'({pattern})', expand=False)\n",
    "\n",
    "# Display the DataFrame to verify the results\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regex pattern to match any string starting with 'x' followed by one or more numeric characters\n",
    "pattern = r'\\bts\\d+'\n",
    "\n",
    "# Extract the model from the title using the regex pattern only if Model is NaN\n",
    "df.loc[df['model'].isna(), 'model'] = df.loc[df['model'].isna(), 'title'].str.extract(f'({pattern})', expand=False)\n",
    "\n",
    "# Display the DataFrame to verify the results\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\bgen\\s\\d+|\\bgen\\d+'\n",
    "\n",
    "# Extract the generation from the title using the regex pattern\n",
    "\n",
    "df['generation'] = df['title'].str.extract(f'({pattern})', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where pattern is present in the title\n",
    "pattern = r'laptop|thinkpad|rails|kit|cable|cables|screws|screw|mount|mounts|mounting|bracket|brackets|bezel|bezels|cover|covers|tray|trays|sled|sleds|psu|power supply|power supplies|fan|fans|caddy|caddies|heatsink'\n",
    "\n",
    "df = df[~df['title'].str.contains(pattern, case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows where price is less than 50\n",
    "#df = df[df['price'] >= 50]\n",
    "\n",
    "# Drop all rows missing a model\n",
    "df = df.dropna(subset=['model'])\n",
    "\n",
    "df = df[['price', 'brand', 'model', 'generation', 'title', 'type', 'link', 'condition', 'seller notes']]\n",
    "\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all unique words in the string in 'title' column\n",
    "print(df['title'].str.split(expand=True).stack().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the df to a new csv file\n",
    "\n",
    "df.to_csv('C://Users//jack//Documents//stock_database_pipeline//price_prediction_pipeline//dataset//update//update_cleantestServers2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat glpi data\n",
    "\n",
    "# Step 1: Read the CSV file into a DataFrame\n",
    "glpi = pd.read_csv('C://Users//jack//Documents//stock_database_pipeline//price_prediction_pipeline//source_csv//glpi_test_data.csv', header=None)\n",
    "\n",
    "# Step 2: Split the single column into multiple columns\n",
    "glpi = glpi[0].str.split(';', expand=True)\n",
    "\n",
    "# Step 3: Set the first row as the header\n",
    "glpi.columns = glpi.iloc[0]\n",
    "glpi = glpi[1:]\n",
    "\n",
    "# Lowercase the column names\n",
    "glpi.columns = glpi.columns.str.lower()\n",
    "\n",
    "# Lowercase all values in the DataFrame\n",
    "glpi = glpi.apply(lambda x: x.str.lower())\n",
    "\n",
    "# Rename the columns\n",
    "glpi.columns = ['brand', 'model', 'status']\n",
    "\n",
    "glpi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip 'poweredge' from the model column\n",
    "#df['model'] = df['model'].str.replace('poweredge', '', case=False)\n",
    "\n",
    "# Strip trailing and leading whitespace from the model column\n",
    "df['model'] = df['model'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status'] = df['price'].astype(float).apply(lambda x: 'sell' if x >= 150 else 'scrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip all whitespace from the 'generation' column\n",
    "\n",
    "df['generation'] = df['generation'].str.replace(' ', '')\n",
    "\n",
    "df['generation'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status'] = df['generation'].apply(lambda x: 'sell' if x in ['gen10', 'gen11'] else 'scrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status'] = df.apply(\n",
    "    lambda row: 'sell' if row['brand'].lower() == 'dell' and (row['model'].lower().startswith('r') or row['model'].lower().startswith('t')) and row['model'].endswith(('30', '40', '50')) else 'scrap', \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status'] = df.apply(\n",
    "    lambda row: 'sell' if row['status'] == 'scrap' and 'ddr4' in row['title'].lower() else row['status'], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "\n",
    "df = df[['status', 'price', 'brand', 'model', 'generation', 'title', 'type', 'link', 'condition', 'seller notes']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the df to a new csv file\n",
    "\n",
    "df.to_csv('C://Users//jack//Documents//stock_database_pipeline//price_prediction_pipeline//source_csv//server_scraped_status.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'model' and 'brand', then calculate the average price and keep the status\n",
    "unique_df = df.groupby(['brand', 'model']).agg(\n",
    "    status=('status', 'first'),  # Assuming status is the same within each group\n",
    "    average_price=('price', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "print(unique_df)\n",
    "\n",
    "# Save the df to a new csv file\n",
    "\n",
    "unique_df.to_csv('C://Users//jack//Documents//stock_database_pipeline//price_prediction_pipeline//source_csv//server_scraped_status_unique.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'avereage_price' column\n",
    "\n",
    "unique_df = unique_df.drop(columns=['average_price'])\n",
    "\n",
    "# Rename columns\n",
    "unique_df.columns = ['Manufacturer', 'Model', 'Status']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "glpi.columns = ['Manufacturer', 'Model', 'Status']\n",
    "\n",
    "glpi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames on the 'Manufacturer' and 'Model' columns\n",
    "merged_df = pd.concat([glpi, unique_df], axis=0, ignore_index=True)\n",
    "\n",
    "# Drop duplicates\n",
    "merged_df = merged_df.drop_duplicates()\n",
    "\n",
    "merged_df.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capitalize the first letter of each word in 'Manufacturer' and 'Model' columns\n",
    "merged_df['Manufacturer'] = merged_df['Manufacturer'].str.title()\n",
    "merged_df['Model'] = merged_df['Model'].str.title()\n",
    "merged_df['Status'] = merged_df['Status'].str.title()\n",
    "\n",
    "\n",
    "# Capitalize the 'E' in 'PowerEdge' in the 'Model' column\n",
    "merged_df['Model'] = merged_df['Model'].str.replace('Poweredge', 'PowerEdge')\n",
    "\n",
    "# Merge all three columns into one separated by a ; character\n",
    "merged_df['Manufacturer;Model;Status'] = merged_df['Manufacturer'] + ';' + merged_df['Model'] + ';' + merged_df['Status']\n",
    "\n",
    "# Drop the 'Manufacturer' and 'Model' columns\n",
    "merged_df = merged_df.drop(columns=['Manufacturer', 'Model', 'Status'])\n",
    "\n",
    "\n",
    "\n",
    "# Save the df to a new csv file\n",
    "merged_df.to_csv('C://Users//jack//Documents//stock_database_pipeline//price_prediction_pipeline//source_csv//glpi_update_server_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
